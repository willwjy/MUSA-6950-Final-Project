{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e48768f-eb17-4ced-aa0b-e0625f141486",
   "metadata": {},
   "source": [
    "# AI Final Project: Mapping Sun Exposure and Extreme Heat Risk in Grove Hall, Boston\n",
    "## William Wang, MUSA 6950, Spring 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0047d428-c74e-4c91-b029-0d9ce5630b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import requests\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from scipy.stats import gaussian_kde\n",
    "import pvlib\n",
    "from rasterio.transform import from_bounds\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from efficientvit.models.utils import resize\n",
    "from efficientvit.seg_model_zoo import create_efficientvit_seg_model\n",
    "from eval_efficientvit_seg_model import ToTensor, get_canvas, CityscapesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d6ec7-4448-4737-92d9-905a3c136341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Step 1: Download Street View Panoramas\n",
    "# -----------------------\n",
    "\n",
    "API_KEY = \"AIzaSyCdxDlGz2ebZBz_tBiBfc9l5k4ERwdFyak\"\n",
    "OUTPUT_FOLDER = \"full_panoramas\"\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# ========== FUNCTION DEFINITIONS ==========\n",
    "\n",
    "def get_pano_metadata(lat, lon):\n",
    "    url = f\"https://maps.googleapis.com/maps/api/streetview/metadata?location={lat},{lon}&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "def download_tile(pano_id, zoom, x, y):\n",
    "    url = f\"https://cbk0.googleapis.com/cbk?output=tile&panoid={pano_id}&zoom={zoom}&x={x}&y={y}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return Image.open(BytesIO(response.content))\n",
    "    return None\n",
    "\n",
    "def download_full_panorama(pano_id, save_path, zoom=3):\n",
    "    tile_size = 512\n",
    "    width, height = 26, 13\n",
    "    panorama = Image.new(\"RGB\", (tile_size * width, tile_size * height))\n",
    "\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            tile = download_tile(pano_id, zoom, x, y)\n",
    "            if tile:\n",
    "                panorama.paste(tile, (x * tile_size, y * tile_size))\n",
    "    panorama.save(save_path)\n",
    "\n",
    "# ========== GENERATE GRID POINTS (Grove Hall) ==========\n",
    "# Rough bounds for Grove Hall neighborhood\n",
    "min_lat, max_lat = 42.310, 42.320\n",
    "min_lon, max_lon = -71.095, -71.075\n",
    "spacing = 0.001  # ~100m spacing\n",
    "\n",
    "lat_points = np.round(np.arange(min_lat, max_lat, spacing), 6)\n",
    "lon_points = np.round(np.arange(min_lon, max_lon, spacing), 6)\n",
    "coords = [(lat, lon) for lat in lat_points for lon in lon_points]\n",
    "\n",
    "# ========== MAIN LOOP ==========\n",
    "metadata_records = []\n",
    "print(\"üì∏ Starting download of full GSV panoramas...\")\n",
    "for lat, lon in tqdm(coords):\n",
    "    try:\n",
    "        meta = get_pano_metadata(lat, lon)\n",
    "        if meta.get(\"status\") == \"OK\" and \"pano_id\" in meta:\n",
    "            pano_id = meta[\"pano_id\"]\n",
    "            date = meta.get(\"date\", \"\")\n",
    "            yaw = meta.get(\"pano_yaw_deg\", \"\")\n",
    "            if yaw is None:\n",
    "              yaw = 0.0\n",
    "            save_path = os.path.join(OUTPUT_FOLDER, f\"{pano_id}.jpg\")\n",
    "\n",
    "            if not os.path.exists(save_path):  # Avoid re-download\n",
    "                download_full_panorama(pano_id, save_path)\n",
    "\n",
    "            metadata_records.append({\n",
    "                \"panoid\": pano_id,\n",
    "                \"lat\": lat,\n",
    "                \"lon\": lon,\n",
    "                \"date\": date,\n",
    "                \"yaw\": yaw\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error at {lat},{lon}: {e}\")\n",
    "        continue\n",
    "        \n",
    "input_file = '/content/drive/MyDrive/Colab Notebooks/data/gsv_panoramas_grovehall_100m.csv'\n",
    "output_file = 'gsv_grovehall_with_yaw_final.csv'\n",
    "\n",
    "with open(input_file, 'r', encoding='utf-8') as fin, open(output_file, 'w', newline='', encoding='utf-8') as fout:\n",
    "    reader = csv.DictReader(fin)\n",
    "    fieldnames = reader.fieldnames + ['heading']\n",
    "    writer = csv.DictWriter(fout, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        pid = row['panoid']\n",
    "        lat = float(row['lat'])\n",
    "        lon = float(row['lon'])\n",
    "\n",
    "        try:\n",
    "            panoids = search_panoramas(lat, lon)\n",
    "            if panoids:\n",
    "                heading = panoids[0].heading\n",
    "            else:\n",
    "                heading = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error at {pid}: {e}\")\n",
    "            heading = None\n",
    "\n",
    "        row['heading'] = heading\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8efd1-6c2d-4c5d-847f-88c8ac46ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Step 2: Train or Load EfficientViT Model\n",
    "# -----------------------\n",
    "\n",
    "def load_model(model_name=\"efficientvit-seg-l1-cityscapes\", weight_path=None):\n",
    "    model = create_efficientvit_seg_model(model_name, pretrained=False).cuda()\n",
    "    checkpoint = torch.load(weight_path)\n",
    "    state_dict = checkpoint.get(\"state_dict\", checkpoint)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def segment_image(model, image_path, output_image_path=None, output_pred_path=None):\n",
    "    image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Resize\n",
    "    crop_size = 512\n",
    "    if h < w:\n",
    "        th = crop_size\n",
    "        tw = math.ceil(w / h * th / 32) * 32\n",
    "    else:\n",
    "        tw = crop_size\n",
    "        th = math.ceil(h / w * tw / 32) * 32\n",
    "    data = cv2.resize(image, (tw, th), interpolation=cv2.INTER_CUBIC) if (h != th or w != tw) else image.copy()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        ToTensor(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    data = transform({\"data\": data, \"label\": np.ones_like(data)})[\"data\"]\n",
    "    data = data.unsqueeze(0).cuda()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        output = model(data)\n",
    "        if output.shape[-2:] != image.shape[:2]:\n",
    "            output = resize(output, size=image.shape[:2])\n",
    "        pred = torch.argmax(output, dim=1).cpu().numpy()[0]\n",
    "\n",
    "    if output_image_path:\n",
    "        canvas = get_canvas(image, pred, CityscapesDataset.class_colors)\n",
    "        Image.fromarray(canvas).save(output_image_path)\n",
    "    if output_pred_path:\n",
    "        np.save(output_pred_path, pred)\n",
    "\n",
    "    return pred\n",
    "\n",
    "model = load_model(\n",
    "    model_name=\"efficientvit-seg-l1-cityscapes\",\n",
    "    weight_path=\"checkpoints/efficientvit_seg_l1_cityscapes.pt\"\n",
    ")\n",
    "\n",
    "#Compute Sky Masks\n",
    "input_folder = \"/mnt/data/stitched_panoramas/\"\n",
    "segmentation_output_folder = \"/mnt/data/segmentation_predictions/\"\n",
    "os.makedirs(segmentation_output_folder, exist_ok=True)\n",
    "\n",
    "stitched_images = glob.glob(os.path.join(input_folder, \"*.jpg\"))\n",
    "\n",
    "for img_path in stitched_images:\n",
    "    panoid = os.path.basename(img_path).replace(\".jpg\", \"\")\n",
    "    seg_output_image_path = f\"/mnt/data/segmentation_results/{panoid}_seg_vis.png\"\n",
    "    seg_output_pred_path = os.path.join(segmentation_output_folder, f\"{panoid}_seg.npy\")\n",
    "\n",
    "    segment_image(\n",
    "        model,\n",
    "        image_path=img_path,\n",
    "        output_image_path=seg_output_image_path,\n",
    "        output_pred_path=seg_output_pred_path\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe59751-f2b6-47c9-8466-9f4c031147b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Step 3: Project to Fisheye with Yaw\n",
    "# -----------------------\n",
    "\n",
    "def pano_to_fisheye(pred_map, yaw_deg, output_size=512):\n",
    "    height, width = pred_map.shape\n",
    "    center = output_size // 2\n",
    "    fisheye = np.zeros((output_size, output_size), dtype=np.uint8)\n",
    "\n",
    "    yaw_rad = np.radians(yaw_deg)\n",
    "    for y in range(output_size):\n",
    "        for x in range(output_size):\n",
    "            dx = x - center\n",
    "            dy = y - center\n",
    "            r = math.sqrt(dx**2 + dy**2)\n",
    "\n",
    "            if r > center or r == 0:\n",
    "                continue\n",
    "\n",
    "            theta = math.atan2(dy, dx) - yaw_rad\n",
    "            phi = (r / center) * (math.pi/2)\n",
    "\n",
    "            if phi > (math.pi/2):\n",
    "                continue\n",
    "\n",
    "            u = (theta % (2 * math.pi)) / (2 * math.pi) * width\n",
    "            v = (phi / (math.pi/2)) * height\n",
    "\n",
    "            if np.isnan(u) or np.isnan(v):\n",
    "                continue\n",
    "\n",
    "            u = int(np.clip(u, 0, width-1))\n",
    "            v = int(np.clip(v, 0, height-1))\n",
    "\n",
    "            fisheye[y, x] = pred_map[v, u]\n",
    "\n",
    "    return fisheye\n",
    "\n",
    "# Batch process all panoramas\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    panoid = row[\"panoid\"]\n",
    "    yaw = row[\"yaw\"]\n",
    "\n",
    "    pred_path = os.path.join(segmentation_folder, f\"{panoid}_stitched_seg.npy\")\n",
    "    if not os.path.exists(pred_path):\n",
    "        print(f\"‚ö†Ô∏è Missing segmentation for {panoid}\")\n",
    "        continue\n",
    "\n",
    "    pred_map = np.load(pred_path)\n",
    "\n",
    "    # Project to fisheye with yaw\n",
    "    fisheye_pred = pano_to_fisheye(pred_map, yaw_deg=yaw, output_size=512)\n",
    "\n",
    "    # Extract sky mask (Cityscapes sky class = 10)\n",
    "    sky_mask = (fisheye_pred == 10).astype(np.uint8)\n",
    "\n",
    "    # Save fisheye sky mask\n",
    "    out_path = os.path.join(fisheye_output_folder, f\"{panoid}_fisheye_sky_mask.png\")\n",
    "    cv2.imwrite(out_path, sky_mask * 255)\n",
    "\n",
    "    print(f\"‚úÖ Saved fisheye sky mask for {panoid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c78732c-8082-42bf-9655-1e164428eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Step 4: Simulate Sun Position & Exposure Calculation\n",
    "# -----------------------\n",
    "\n",
    "def get_daily_sun_positions(lat, lon, date, freq=\"10min\"):\n",
    "    times = pd.date_range(f\"{date} 04:00\", f\"{date} 20:00\", freq=freq, tz=\"America/New_York\")\n",
    "    solpos = pvlib.solarposition.get_solarposition(times, lat, lon)\n",
    "    return solpos[['zenith', 'azimuth']]\n",
    "\n",
    "def calculate_sun_exposure_for_day(sky_mask, solpos, image_size=512):\n",
    "    center = image_size // 2\n",
    "    radius = center\n",
    "    exposed_minutes = 0\n",
    "\n",
    "    for _, row in solpos.iterrows():\n",
    "        zenith = row[\"zenith\"]\n",
    "        azimuth = row[\"azimuth\"]\n",
    "        if zenith > 90:\n",
    "            continue\n",
    "\n",
    "        r = (zenith / 90) * radius\n",
    "        theta = np.radians(azimuth)\n",
    "        x = int(center + r * np.sin(theta))\n",
    "        y = int(center - r * np.cos(theta))\n",
    "\n",
    "        if 0 <= x < image_size and 0 <= y < image_size:\n",
    "            if sky_mask[y, x] > 0:\n",
    "                exposed_minutes += 10\n",
    "\n",
    "    return exposed_minutes / 60  # convert to hours\n",
    "\n",
    "def calculate_average_july_exposure(sky_mask_path, lat, lon):\n",
    "    sky_mask = cv2.imread(sky_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    sky_mask = (sky_mask > 127).astype(np.uint8)\n",
    "\n",
    "    total_hours = 0\n",
    "    for day in range(1, 32):\n",
    "        date = f\"2024-07-{day:02d}\"\n",
    "        solpos = get_daily_sun_positions(lat, lon, date)\n",
    "        total_hours += calculate_sun_exposure_for_day(sky_mask, solpos)\n",
    "\n",
    "    return total_hours / 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5bb478-a369-461b-84c6-906514b9785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Step 5: Raster Density Map Generation\n",
    "# -----------------------\n",
    "\n",
    "#Estimate Extreme Heat Risk\n",
    "\n",
    "# Load sun exposure results\n",
    "df = pd.read_csv(\"/mnt/data/july_avg_sun_exposure.csv\")\n",
    "\n",
    "# Define a function to classify heat risk\n",
    "def classify_heat_risk(avg_sun_hours):\n",
    "    if avg_sun_hours > 4:\n",
    "        return \"High\"\n",
    "    elif avg_sun_hours > 2:\n",
    "        return \"Moderate\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "# Apply classification\n",
    "df['heat_risk'] = df['avg_sun_hours'].apply(classify_heat_risk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
